{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions (read table, make list of GCX and protein ID)\n",
    "GCX means either GCA or GCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_table(file):\n",
    "    df=pd.read_csv(file, sep=\"\\t\") # Read file intp script\n",
    "    df=df.dropna() # Delete all enterys with 'NaN' in it\n",
    "    df=df.drop(df.columns[0:1],axis=1) #'Unnamed: 0''index'\n",
    "    df=df.drop_duplicates()\n",
    "    df=df.sort_values(by='Organism')\n",
    "    df=df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# df.drop(df.columns[i], axis=1)\n",
    "def get_GCX_id(table):\n",
    "    GCX_id=table['GCX_id'].values.tolist() # Extract GCF IDs\n",
    "    return GCX_id\n",
    "\n",
    "def get_protein_id(table):\n",
    "    proteinID=table['proteinID'].values.tolist() #Extract protein IDs\n",
    "    modified_proteinID=[]\n",
    "    for i in proteinID:\n",
    "        new=i.split('.')\n",
    "        modified_proteinID.append(new[0])\n",
    "    return modified_proteinID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Organism       proteinID           GCX_id\n",
      "0          Acaryochloris marina MBIC11017  WP_012166727.1  GCF_000018105.1\n",
      "1                 Acidobacteria bacterium      RMH16883.1  GCA_003697015.1\n",
      "2                 Acidobacteria bacterium      PYT36116.1  GCA_003223075.1\n",
      "3                 Acidobacteria bacterium      PYT33732.1  GCA_003223075.1\n",
      "4                 Acidobacteria bacterium      PYQ38222.1  GCA_003222295.1\n",
      "..                                    ...             ...              ...\n",
      "478             unclassified Streptomyces  WP_093526515.1  GCF_900090115.1\n",
      "479             unclassified Streptomyces  WP_103492571.1  GCF_002910775.2\n",
      "480             unclassified Streptomyces  WP_099279319.1  GCF_002705975.1\n",
      "481   unclassified Streptomyces(MspMP-M5)  WP_106731933.1  GCF_000373585.1\n",
      "482  unclassified Streptomyces(OspMP-M45)  WP_093675912.1  GCF_900090065.1\n",
      "\n",
      "[483 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "table=read_table('blastp_500_all_data_no_duplicates_sorted.txt')\n",
    "# table.to_csv('blastp_500_all_data_no_duplicates_sorted.txt', sep='\\t')\n",
    "print(table)\n",
    "GCX_id=get_GCX_id(table)\n",
    "# print(GCF_id)\n",
    "proteinID=get_protein_id(table)\n",
    "# print(table['proteinID'].nunique())\n",
    "# print(table['proteinID'])\n",
    "# print(table['GCX_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make function that finds the right files a specific folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_GCX_files(GCX_id):\n",
    "    GCX_matches=[]\n",
    "    for i in GCX_id:\n",
    "        filename = i # This is our known part of the file name = search query\n",
    "        direc = r\"C:\\Users\\ASUS\\Desktop\\extract100kb_500_hits\\genomic_fna\" # Look in this folder\n",
    "        GCX_match = [ fname for fname in os.listdir(direc) if fname.startswith(filename) ] # The search. found online. Called \"search method\" in the notes\n",
    "        if len(GCX_match) < 1:\n",
    "            GCX_matches.append('NaN')\n",
    "        if len(GCX_match) == 1:\n",
    "            GCX_match = ''.join(GCX_match)\n",
    "            GCX_matches.append(GCX_match)\n",
    "        elif len(GCX_match) > 1:\n",
    "            GCX_match = ''.join(GCX_match)\n",
    "            GCX_matches.append(GCX_match)            \n",
    "    return GCX_matches\n",
    "\n",
    "def get_gbprotein_files(proteinID):\n",
    "    gbprotein_matches=[]\n",
    "    for i in proteinID:\n",
    "        filename = i # This is our known part of the file name = search query\n",
    "        direc = r\"C:\\Users\\ASUS\\Desktop\\extract100kb_500_hits\\annotation-protein-gbfiles\"\n",
    "        gbprotein_match = [ fname for fname in os.listdir(direc) if fname.startswith(filename) ]\n",
    "        if len(gbprotein_match) < 1:\n",
    "            gbprotein_matches.append('NaN')\n",
    "#             print(i)\n",
    "        if len(gbprotein_match) == 1:\n",
    "            gbprotein_match = ''.join(gbprotein_match)\n",
    "            gbprotein_matches.append(gbprotein_match)\n",
    "        elif len(gbprotein_match) > 1:\n",
    "            gbprotein_match = ''.join(gbprotein_match)\n",
    "            gbprotein_matches.append(gbprotein_match)\n",
    "    return gbprotein_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCX_files=get_GCX_files(GCX_id)\n",
    "# print(len(GCX_files))\n",
    "# gbprotein_files=get_gbprotein_files(proteinID)\n",
    "# print(len(gbprotein_files))\n",
    "# # print(table[60:61])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function that returns the right assembly from a GCX file\n",
    "It needs the GCF file and the right assembly nr (sequence_id) from the gbprotein file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sequence(GCX, sequence_id):\n",
    "    GCX = r\"C:\\Users\\ASUS\\Desktop\\extract100kb_500_hits\\genomic_fna\\{}\".format(GCX) \n",
    "    for record in SeqIO.parse(GCX,\"fasta\"): # Find the right assembly version in the GCF file\n",
    "#         print(record.id)\n",
    "        if record.id.find(sequence_id) >= 0:\n",
    "            sequence=record.seq\n",
    "            return sequence\n",
    "        \n",
    "# test=find_sequence(GCF_files[230],'NZ_KI912153.1')\n",
    "# print(test)\n",
    "# print(GCF_files[number])\n",
    "# print(gbprotein_files[179])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that cuts the right sequence + 100kb on each side (or as much it allows)\n",
    "List is None if no match between gbprotein file and assembly file. That means that it can only cut if there is a match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "def list_of_organism_seq_id_and_sequence(genbank_rec, protein_id, GCX):\n",
    "    genbank_rec = r\"C:\\Users\\ASUS\\Desktop\\extract100kb_500_hits\\annotation-protein-gbfiles\\{}\".format(genbank_rec)\n",
    "#     GCX = r\"C:\\Users\\ASUS\\Desktop\\extract100kb_500_hits\\genomic_fna\\{}\".format(GCF) \n",
    "    if genbank_rec == 'NaN':\n",
    "        return 'gbprotein file not found'\n",
    "    for rec in SeqIO.parse(genbank_rec,\"gb\"): # Find the locus of the protein of interest\n",
    "        organism=rec.annotations['organism']\n",
    "        sequence_id=rec.id\n",
    "#         print(sequence_id)\n",
    "        sequence=find_sequence(GCX,sequence_id)\n",
    "#         print(sequence)\n",
    "        if sequence != None:\n",
    "            if rec.features:\n",
    "#                 print(rec.features)\n",
    "                for feature in rec.features:\n",
    "                    if feature.type == \"CDS\": # Find all CDS\n",
    "#                         print(feature.qualifiers['protein_id'])\n",
    "                        if 'protein_id' in feature.qualifiers: # Check all fields called 'protein_id'\n",
    "#                             print(feature.qualifiers['protein_id'])\n",
    "                            if any(protein_id in s for s in feature.qualifiers['protein_id']): # If our protein_id is found\n",
    "                                location = [int(feature.location.start),int(feature.location.end)] # Extract the location\n",
    "                                strand = feature.location.strand # Find out which strand (template or compliment (+/-))\n",
    "#                                 print(strand)\n",
    "                                if sequence == None:\n",
    "                                    return 'problem with sequence'\n",
    "                                if strand == -1:\n",
    "                                    if location[0]-100000 < 0 and location[1]+100000 > len(sequence):\n",
    "                                        return [organism, sequence_id, ''.join(feature.qualifiers['protein_id']), sequence.reverse_complement(),location]\n",
    "                                    elif location[0]-100000 < 0:\n",
    "                                        return [organism, sequence_id, ''.join(feature.qualifiers['protein_id']), sequence[0:location[1]+100000].reverse_complement(),location] \n",
    "                                    elif location[1]+100000 > len(sequence):\n",
    "                                        return [organism, sequence_id, ''.join(feature.qualifiers['protein_id']), sequence[location[0]-100000:len(sequence)].reverse_complement(),location] \n",
    "                                    else :\n",
    "                                        return [organism, sequence_id, ''.join(feature.qualifiers['protein_id']), sequence[location[0]-100000:location[1]+100000].reverse_complement(),location] \n",
    "                                if strand == 1:\n",
    "                                    if location[0]-100000 < 0 and location[1]+100000 > len(sequence):\n",
    "                                        return [organism, sequence_id, ''.join(feature.qualifiers['protein_id']), sequence.reverse_complement(),location]\n",
    "                                    elif location[0]-100000 < 0:\n",
    "                                        return [organism, sequence_id, ''.join(feature.qualifiers['protein_id']), sequence[0:location[1]+100000],location] \n",
    "                                    elif location[1]+100000 > len(sequence):\n",
    "                                        return [organism, sequence_id, ''.join(feature.qualifiers['protein_id']), sequence[location[0]-100000:len(sequence)],location] \n",
    "                                    else :\n",
    "                                        return [organism, sequence_id, ''.join(feature.qualifiers['protein_id']), sequence[location[0]-100000:location[1]+100000],location] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function\n",
    "This ties it all together and returnes a lst of lst, which is turned into a dataframe, which holds all data (organism, assembly_nr, protein_ID,motif sequence, motif locus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def all(file):\n",
    "    lst_of_lst=[]\n",
    "    table=read_table(file)\n",
    "    table=table # Problemer med nr. 27\n",
    "    GCX_id=get_GCX_id(table)\n",
    "    proteinID=get_protein_id(table)\n",
    "    GCX_files=get_GCX_files(GCX_id)\n",
    "    gbprotein_files=get_gbprotein_files(proteinID)\n",
    "    counter = 0\n",
    "    for (i,j,k) in zip(gbprotein_files, proteinID, GCX_files):\n",
    "        if i != 'NaN' and i != '' and k != 'NaN':\n",
    "            lst=list_of_organism_seq_id_and_sequence(i, j, k)\n",
    "            if lst != None:\n",
    "                if len(lst)==5:\n",
    "                    lst_of_lst.append(lst)\n",
    "        counter += 1\n",
    "    matches = len(lst_of_lst)\n",
    "    return lst_of_lst\n",
    "\n",
    "filtered_results=all('blastp_500_all_data_no_duplicates_sorted.txt')\n",
    "df=pd.DataFrame.from_records(filtered_results, columns=['ORGANISM','ASSEMBLY_NR','PROTEIN_ID','M_SEQUENCE','M_LOCUS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           ORGANISM        ASSEMBLY_NR      PROTEIN_ID  \\\n",
      "0    Acaryochloris marina MBIC11017        NC_009926.1  WP_012166727.1   \n",
      "1           Acidobacteria bacterium     RFGL01000382.1      RMH16883.1   \n",
      "2           Acidobacteria bacterium     QHXV01000007.1      PYT36116.1   \n",
      "3           Acidobacteria bacterium     QHXV01000085.1      PYT33732.1   \n",
      "4           Acidobacteria bacterium     QHVP01000632.1      PYQ38222.1   \n",
      "..                              ...                ...             ...   \n",
      "475      Streptomyces sp. AmelKG-A3  NZ_FMYR01000011.1  WP_093526515.1   \n",
      "476           Streptomyces sp. SM18      NZ_CP029342.1  WP_103492571.1   \n",
      "477    Streptomyces sp. AmelKG-E11A  NZ_AQRJ01000022.1  WP_099279319.1   \n",
      "478       Streptomyces sp. MspMP-M5      NZ_KB891904.1  WP_106731933.1   \n",
      "479      Streptomyces sp. OspMP-M45  NZ_FLTP01000008.1  WP_093675912.1   \n",
      "\n",
      "                                            M_SEQUENCE           M_LOCUS  \n",
      "0    (C, A, A, C, A, T, T, A, T, T, C, T, C, A, A, ...  [201841, 206839]  \n",
      "1    (G, C, G, T, C, G, C, C, C, T, G, C, C, C, G, ...    [17282, 22931]  \n",
      "2    (A, A, A, C, C, T, T, G, T, T, C, G, C, A, G, ...      [3901, 8533]  \n",
      "3    (A, C, C, G, G, C, G, A, A, C, C, C, A, C, A, ...     [6227, 10883]  \n",
      "4    (C, T, G, G, A, G, C, T, G, G, G, G, C, C, G, ...         [0, 3214]  \n",
      "..                                                 ...               ...  \n",
      "475  (A, G, C, C, C, G, G, T, A, A, C, G, G, G, T, ...  [200612, 206372]  \n",
      "476  (C, G, G, G, T, C, A, C, C, C, A, C, A, C, G, ...  [748497, 754257]  \n",
      "477  (G, A, C, T, G, T, G, A, C, C, C, A, C, C, A, ...    [22333, 28120]  \n",
      "478  (G, C, G, C, C, T, T, G, G, C, C, T, G, C, T, ...    [17124, 22878]  \n",
      "479  (T, C, G, C, T, G, T, A, G, G, C, C, A, G, G, ...   [95728, 101488]  \n",
      "\n",
      "[480 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write fastafile\n",
    "All-in-one file + 4 files of around 100 sequences each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write file with all sequences\n",
    "write_all=open(r'C:\\Users\\ASUS\\Desktop\\extract100kb_500_hits\\Found_sequences\\motif_plus_100kb_tails_all.fa','w')\n",
    "write0_100=open(r'C:\\Users\\ASUS\\Desktop\\extract100kb_500_hits\\Found_sequences\\motif_plus_100kb_tails_all0_100.fa','w')\n",
    "write100_200=open(r'C:\\Users\\ASUS\\Desktop\\extract100kb_500_hits\\Found_sequences\\motif_plus_100kb_tails_all100_200.fa','w')\n",
    "write200_300=open(r'C:\\Users\\ASUS\\Desktop\\extract100kb_500_hits\\Found_sequences\\motif_plus_100kb_tails_all200_300.fa','w')\n",
    "write300_400=open(r'C:\\Users\\ASUS\\Desktop\\extract100kb_500_hits\\Found_sequences\\motif_plus_100kb_tails_all300_400.fa','w')\n",
    "write400_500=open(r'C:\\Users\\ASUS\\Desktop\\extract100kb_500_hits\\Found_sequences\\motif_plus_100kb_tails_all400_end.fa','w')\n",
    "\n",
    "for i in df['PROTEIN_ID']: # If protein id from new result \n",
    "        write_all.write(\">{}\".format(i)) # Header\n",
    "        write_all.write(\"\\n\")\n",
    "        write_all.write(str(df.loc[df['PROTEIN_ID'] == i]['M_SEQUENCE'].values[0])) #Find row where protein ID is, and extract str(sequence).\n",
    "        write_all.write(\"\\n\")\n",
    "write_all.close()\n",
    "\n",
    "for i in df['PROTEIN_ID'][0:100]: # If protein id from new result \n",
    "        write0_100.write(\">{}\".format(i)) # Header\n",
    "        write0_100.write(\"\\n\")\n",
    "        write0_100.write(str(df.loc[df['PROTEIN_ID'] == i]['M_SEQUENCE'].values[0])) #Find row where protein ID is, and extract str(sequence).\n",
    "        write0_100.write(\"\\n\")\n",
    "write0_100.close()\n",
    "\n",
    "for i in df['PROTEIN_ID'][100:200]: # If protein id from new result \n",
    "        write100_200.write(\">{}\".format(i)) # Header\n",
    "        write100_200.write(\"\\n\")\n",
    "        write100_200.write(str(df.loc[df['PROTEIN_ID'] == i]['M_SEQUENCE'].values[0])) #Find row where protein ID is, and extract str(sequence).\n",
    "        write100_200.write(\"\\n\")\n",
    "write100_200.close()\n",
    "\n",
    "for i in df['PROTEIN_ID'][200:300]: # If protein id from new result \n",
    "        write200_300.write(\">{}\".format(i)) # Header\n",
    "        write200_300.write(\"\\n\")\n",
    "        write200_300.write(str(df.loc[df['PROTEIN_ID'] == i]['M_SEQUENCE'].values[0])) #Find row where protein ID is, and extract str(sequence).\n",
    "        write200_300.write(\"\\n\")\n",
    "write200_300.close()\n",
    "\n",
    "for i in df['PROTEIN_ID'][300:400]: # If protein id from new result \n",
    "        write300_400.write(\">{}\".format(i)) # Header\n",
    "        write300_400.write(\"\\n\")\n",
    "        write300_400.write(str(df.loc[df['PROTEIN_ID'] == i]['M_SEQUENCE'].values[0])) #Find row where protein ID is, and extract str(sequence).\n",
    "        write300_400.write(\"\\n\")\n",
    "write300_400.close()\n",
    "\n",
    "for i in df['PROTEIN_ID'][400::]: # If protein id from new result \n",
    "        write400_500.write(\">{}\".format(i)) # Header\n",
    "        write400_500.write(\"\\n\")\n",
    "        write400_500.write(str(df.loc[df['PROTEIN_ID'] == i]['M_SEQUENCE'].values[0])) #Find row where protein ID is, and extract str(sequence).\n",
    "        write400_500.write(\"\\n\")\n",
    "write400_500.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats\n",
    "missing_data = read data from file, make a df with all unique protein ids, deleted from read_table. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv('blastp_500_all_data_no_duplicates_sorted.txt', sep=\"\\t\")\n",
    "\n",
    "def missing_data(file):\n",
    "    df=pd.read_csv(file, sep=\"\\t\")\n",
    "    df1=df[df.isna().any(axis=1)] # Find all data with NaN\n",
    "    new_df=df1.dropna(subset=['proteinID']) # Delete all entries, where NaN is present in protein ID.\n",
    "    unique=new_df['proteinID'].unique()\n",
    "    del new_df['Unnamed: 0']\n",
    "    return new_df\n",
    "\n",
    "missing=missing_data('blastp_500_all_data_no_duplicates_sorted.txt')\n",
    "\n",
    "proteinID_not_found=[]\n",
    "for i in table['proteinID'].values: # If protein ID is used in the script\n",
    "    if i not in df['PROTEIN_ID'].values and i not in proteinID_not_found: # But not found in the results  and i not in proteinID_not_found\n",
    "        proteinID_not_found.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProteinIDs from Daniela's table: 493\n",
      "ProteinIDs with no GCFid (10)\n",
      "                                           Organism       proteinID GCX_id\n",
      "46                            Bacillus sp. NSP2.1**  WP_026557213.1    NaN\n",
      "47                            Bacillus sp. NSP2.1**  WP_026557206.1    NaN\n",
      "82                       Candidatus Kentron sp. FW*      VFJ75372.1    NaN\n",
      "112                  Deltaproteobacteria bacterium*      HEB89883.1    NaN\n",
      "157                  Gammaproteobacteria bacterium*      HEB56032.1    NaN\n",
      "225            Micromonospora purpureochromogenes**  WP_030498975.1    NaN\n",
      "226            Micromonospora purpureochromogenes**  WP_030502634.1    NaN\n",
      "277                             Myxococcus fulvus**  WP_046711868.1    NaN\n",
      "302  Nostoc sp. 'Peltigera membranacea cyanobiont'*      ADA69241.1    NaN\n",
      "337             Planktothrix prolifica NIVA-CYA 98*      CAQ48282.1    NaN\n",
      "ProteinIDs with problems 3\n",
      "['MAG31691.1', 'CUM62319.1', 'ACG63859.1']\n",
      "ProteinIDs found 480\n"
     ]
    }
   ],
   "source": [
    "print(\"ProteinIDs from Daniela's table:\",df2['proteinID'].nunique())\n",
    "print(\"ProteinIDs with no GCFid\",'({})'.format(len(missing))) #print(missing)\n",
    "print(missing)\n",
    "print(\"ProteinIDs with problems\", len(proteinID_not_found))\n",
    "print(proteinID_not_found)\n",
    "print(\"ProteinIDs found\", df['PROTEIN_ID'].nunique())\n",
    "# print(table.loc[table['proteinID'] =='HAI15717.1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
